{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyldpc as ldpc\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from utils_f import load_code\n",
    "import os\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_filename = './source/hamming.alist'\n",
    "code = load_code(H_filename)\n",
    "H = code.H\n",
    "G = code.G\n",
    "var_degrees = code.var_degrees\n",
    "chk_degrees = code.chk_degrees\n",
    "num_edges = code.num_edges\n",
    "u = code.u\n",
    "d = code.d\n",
    "n = code.n\n",
    "m = code.m\n",
    "k = code.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, num_iterations = 5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.W_cv = torch.nn.Parameter(torch.randn((num_iterations, num_edges)))\n",
    "        self.W_cv.requires_grad = True\n",
    "        self.B_cv = torch.nn.Parameter(torch.randn((num_iterations, num_edges)))\n",
    "        self.B_cv.requires_grad = True\n",
    "        self.W_vc = torch.nn.Parameter(torch.randn((num_iterations, num_edges)))\n",
    "        self.W_vc.requires_grad = True\n",
    "        \n",
    "        self.num_iterations = num_iterations\n",
    "        \n",
    "    def forward(self, soft_input):\n",
    "        soft_input = soft_input.T           # TODO! Fix matrix dimensions inside functions\n",
    "        # print(soft_input.shape)\n",
    "        cv = torch.zeros((num_edges, soft_input.shape[1]))\n",
    "        for iteration in range(0, self.num_iterations):\n",
    "            vc = self.compute_vc(cv, soft_input, iteration)\n",
    "            cv = self.compute_cv(vc, iteration)\n",
    "            soft_input = self.marginalize(soft_input, cv)\n",
    "        output = torch.sigmoid(soft_input)\n",
    "        output = output.T\n",
    "        # output = soft_input\n",
    "        return output\n",
    "\n",
    "        \n",
    "    def compute_vc(self, cv, soft_input, iteration):\n",
    "        edges = []\n",
    "        for i in range(0, n):\n",
    "            for j in range(0, var_degrees[i]):\n",
    "                edges.append(i)\n",
    "        # print(soft_input.shape, len(edges), edges)\n",
    "        reordered_soft_input = torch.index_select(soft_input, 0, torch.tensor(edges).to(device))\n",
    "\n",
    "        vc = torch.zeros((num_edges, cv.shape[1])).to(device)\n",
    "        counter = 0\n",
    "        edge_order = []\n",
    "\n",
    "        for i in range(0, n): # for each variable node v\n",
    "            for j in range(0, var_degrees[i]):\n",
    "                edge_order.append(d[i][j])\n",
    "                extrinsic_edges = []\n",
    "                for jj in range(0, var_degrees[i]):\n",
    "                    if jj != j: # extrinsic information only\n",
    "                        extrinsic_edges.append(d[i][jj])\n",
    "                # if the list of edges is not empty, add them up\n",
    "                if extrinsic_edges:\n",
    "                    # print(cv.shape, len(extrinsic_edges), extrinsic_edges)\n",
    "                    temp = torch.index_select(cv.to(device), 0, torch.tensor(extrinsic_edges).to(device))\n",
    "                    temp = torch.sum(temp, 0)\n",
    "                else:\n",
    "                    temp = torch.zeros(cv.shape[1])\n",
    "\n",
    "                temp = temp.to(device)\n",
    "                vc[counter] = temp\n",
    "        \n",
    "        new_order = np.zeros(num_edges).astype(int)\n",
    "        new_order[edge_order] = np.arange(0, num_edges)\n",
    "        vc = torch.index_select(vc, 0, torch.tensor(new_order).to(device))\n",
    "        vc += reordered_soft_input * torch.tile(torch.reshape(self.W_vc[iteration], (-1,1)), (1, cv.shape[1]))       # add soft inputs of the previous iterations!\n",
    "        return vc \n",
    "\n",
    "    def compute_cv(self, vc, iteration):\n",
    "        cv_list = []\n",
    "        prod_list = []\n",
    "        min_list = []\n",
    "        edge_order = []\n",
    "        for i in range(0, m): # for each check node c\n",
    "            for j in range(0, chk_degrees[i]):\n",
    "                edge_order.append(u[i][j])\n",
    "                extrinsic_edges = []\n",
    "                for jj in range(0, chk_degrees[i]):\n",
    "                    if jj != j:\n",
    "                        extrinsic_edges.append(u[i][jj])\n",
    "                temp = torch.index_select(vc.to(device),0,torch.tensor(extrinsic_edges).to(device))\n",
    "                temp1 = torch.prod(torch.sign(temp),0)\n",
    "                temp2 = torch.min(torch.abs(temp),0)[0]\n",
    "                prod_list.append(temp1)\n",
    "                min_list.append(temp2)\n",
    "        prods = torch.stack(prod_list)\n",
    "        mins = torch.stack(min_list)\n",
    "        mins = torch.relu(mins - torch.tile(torch.reshape(self.B_cv[iteration], (-1,1)), (1, vc.shape[1])))\n",
    "        cv = prods * mins\n",
    "        new_order = np.zeros(num_edges).astype(int)\n",
    "        new_order[edge_order] = np.array(range(0,num_edges)).astype(int)\n",
    "        cv = torch.index_select(cv, 0, torch.tensor(new_order).to(device))\n",
    "        cv = cv * torch.tile(torch.reshape(self.W_cv[iteration], (-1,1)), (1, vc.shape[1]))\n",
    "        return cv\n",
    "\n",
    "    # combine messages to get posterior LLRs\n",
    "    def marginalize(self, soft_input, cv):\n",
    "        weighted_soft_input = soft_input\n",
    "        soft_output = []\n",
    "        for i in range(0,n):\n",
    "            edges = []\n",
    "            for e in range(0,var_degrees[i]):\n",
    "                edges.append(d[i][e])\n",
    "            temp = torch.index_select(cv,0,torch.tensor(edges).to(device))\n",
    "            temp = torch.sum(temp, 0)\n",
    "            soft_output.append(temp)\n",
    "        soft_output = torch.stack(soft_output)\n",
    "        soft_output = weighted_soft_input + soft_output\n",
    "        return soft_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(loader, clf, criterion, opt):\n",
    "    clf.train(True)\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    correct = 0\n",
    "    # load batch\n",
    "    for model_input, target in loader:\n",
    "        # move data to device\n",
    "        model_input = model_input.to(device)\n",
    "        target = target.to(device)\n",
    "        # calculate outputs, loss and accuracy\n",
    "        model_output = clf(model_input)\n",
    "        loss = criterion(model_output, target)\n",
    "        # print(model_input[0], model_output[0])\n",
    "        avg_loss += loss\n",
    "        correct += torch.count_nonzero(torch.heaviside(model_output-0.5, torch.tensor([0.]).to(device)).to(device) == target)\n",
    "        # calculate grad, upd weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    avg_loss = avg_loss / len(loader)\n",
    "    avg_acc = correct / len(loader.dataset)\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "            \n",
    "            \n",
    "                        \n",
    "def epoch_test(loader, clf, criterion):\n",
    "    clf.eval()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    correct = 0\n",
    "    # load batch\n",
    "    for model_input, target in loader:\n",
    "        # move data to device\n",
    "        model_input = model_input.to(device)\n",
    "        target = target.to(device)\n",
    "        # calculate outputs, loss and accuracy\n",
    "        model_output = clf(model_input)\n",
    "        loss = criterion(model_output, target)\n",
    "        avg_loss += loss\n",
    "        correct += torch.count_nonzero(torch.heaviside(model_output-0.5, torch.tensor([0.]).to(device)).to(device) == target)\n",
    "    avg_loss = avg_loss / len(loader)\n",
    "    avg_acc = correct / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def train(train_loader, test_loader, clf, criterion, opt, n_epochs=50):\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_loss, train_acc = epoch_train(train_loader, clf, criterion, opt)\n",
    "        test_loss, test_acc = epoch_test(test_loader, clf, criterion)\n",
    "\n",
    "        if (np.mod(epoch+1,2)==0):\n",
    "            print(f'[Epoch {epoch + 1}] train loss: {train_loss:.3f}; train acc: {train_acc:.2f}; ' + \n",
    "                  f'test loss: {test_loss:.3f}; test acc: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 100000\n",
    "\n",
    "# messages = np.random.randint(0,2,[train_size,k])\n",
    "# codewords = messages @ G % 2\n",
    "# BPSK_codewords = (0.5 - codewords.astype(np.float32)) * 2.0\n",
    "# soft_input = np.zeros_like(BPSK_codewords)\n",
    "\n",
    "\n",
    "# soft_input = torch.ones((train_size, n))\n",
    "# SNRs = np.arange(-10,6)\n",
    "# for i in range(0,len(SNRs)):\n",
    "#     sigma = np.sqrt(1. / (2 * (np.float(k)/np.float(n)) * 10**(SNRs[i]/10)))\n",
    "#     noise = sigma * np.random.randn(train_size//len(SNRs),n)\n",
    "#     start_idx = train_size*i//len(SNRs)\n",
    "#     end_idx = train_size*(i+1)//len(SNRs)\n",
    "#     soft_input[start_idx:end_idx,:] += noise\n",
    "\n",
    "def gen():\n",
    "    messages = np.random.randint(0,2,[train_size,k])\n",
    "    codewords = messages @ G % 2\n",
    "    BPSK_codewords = (0.5 - codewords.astype(np.float32)) * 2.0\n",
    "    soft_input = np.zeros_like(BPSK_codewords)\n",
    "    SNRs = np.arange(1,6)\n",
    "    for i in range(0,len(SNRs)):\n",
    "        sigma = np.sqrt(1. / (2 * (np.float(k)/np.float(n)) * 10**(SNRs[i]/10)))\n",
    "        noise = sigma * np.random.randn(train_size//len(SNRs),n)\n",
    "        start_idx = train_size*i//len(SNRs)\n",
    "        end_idx = train_size*(i+1)//len(SNRs)\n",
    "        soft_input[start_idx:end_idx,:] = BPSK_codewords[start_idx:end_idx,:] + noise\n",
    "    return soft_input, codewords\n",
    "    \n",
    "    \n",
    "    \n",
    "def update_loaders():\n",
    "\n",
    "\n",
    "    soft_input_train, codewords_train = gen()\n",
    "    train_X = torch.Tensor(soft_input_train) # transform to torch tensor\n",
    "    train_y = torch.Tensor(codewords_train)\n",
    "    training_dataset = torch.utils.data.TensorDataset(train_X, train_y) # create your datset\n",
    "    training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=1000, shuffle=True) # create your dataloader\n",
    "\n",
    "\n",
    "    soft_input_test, codewords_test = gen()\n",
    "    test_X = torch.Tensor(soft_input_test) # transform to torch tensor\n",
    "    test_y = torch.Tensor(codewords_test)\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_X, test_y) # create your datset\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True) # create your dataloader\n",
    "    return training_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(num_iterations=5).to(device)\n",
    "opt = torch.optim.Adam(decoder.parameters(), lr=0.1)\n",
    "# opt = torch.optim.SGD(decoder.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▉                                                                                                                   | 2/60 [00:13<06:39,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss: 5.879; train acc: 6.49; test loss: 5.866; test acc: 6.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▉                                                                                                               | 4/60 [00:27<06:34,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] train loss: 5.855; train acc: 6.54; test loss: 5.840; test acc: 6.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▉                                                                                                           | 6/60 [00:42<06:23,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] train loss: 5.853; train acc: 6.55; test loss: 5.836; test acc: 6.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▊                                                                                                       | 8/60 [00:56<06:07,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] train loss: 5.848; train acc: 6.56; test loss: 5.834; test acc: 6.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▊                                                                                                     | 9/60 [01:03<05:58,  7.04s/it]"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(f'{i+1}/5')\n",
    "    training_loader, test_loader = update_loaders()\n",
    "    train(training_loader, test_loader, decoder, criterion, opt, n_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 100000\n",
    "SNRs = np.arange(-10,10)\n",
    "results_hard = torch.zeros(len(SNRs))\n",
    "results_nn = torch.zeros(len(SNRs))\n",
    "\n",
    "decoder.eval()\n",
    "messages = torch.randint(0, 2, (test_size, k))\n",
    "codewords = messages @ G % 2\n",
    "codewords = codewords.to(device)\n",
    "BPSK_codewords = (0.5 - codewords) * 2\n",
    "for i, snr in enumerate(SNRs):\n",
    "    sigma = np.sqrt(1. / (2 * (np.float(k)/np.float(n)) * 10**(snr/10)))\n",
    "    noise = torch.tensor(sigma).to(device) * torch.randn(test_size, n).to(device)\n",
    "    soft_input = BPSK_codewords + noise\n",
    "    correct_hard = torch.count_nonzero((-(torch.sign(soft_input) - 1)/2) == codewords)\n",
    "    correct_nn = torch.count_nonzero(torch.heaviside(decoder(soft_input) - 0.5, torch.tensor([0.]).to(device)) == codewords)\n",
    "    print(f'SNR: {snr}, correct: {correct_nn}, errors: {test_size*n - correct_nn}')\n",
    "    results_hard[i] = correct_hard\n",
    "    results_nn[i] = correct_nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.semilogy(SNRs, (test_size*n - results_nn.numpy()) / (test_size*n), label='NN')\n",
    "plt.semilogy(SNRs, (test_size*n - results_hard.numpy()) / (test_size*n), label='hard decision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder(soft_input)[0] - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codewords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.W_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
