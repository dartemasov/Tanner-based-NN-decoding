{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow.python.framework import ops\n",
    "from helper_functions import load_code, syndrome\n",
    "import os\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1221\n",
    "np.random.seed(seed)\n",
    "snr_lo = 1\n",
    "snr_hi = 6\n",
    "snr_step = 1\n",
    "min_frame_errors = 100\n",
    "max_frames = 100000000\n",
    "# num_iterations = 5\n",
    "H_filename = './codes/hamming.alist'\n",
    "G_filename = './codes/hamming.gmat'\n",
    "output_filename = 'out_file'\n",
    "L = 0.5\n",
    "steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = load_code(H_filename, G_filename)\n",
    "H = code.H\n",
    "G = code.G\n",
    "var_degrees = code.var_degrees\n",
    "chk_degrees = code.chk_degrees\n",
    "num_edges = code.num_edges\n",
    "u = code.u\n",
    "d = code.d\n",
    "n = code.n\n",
    "m = code.m\n",
    "k = code.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, num_iterations = 5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.W_cv = torch.nn.Parameter(torch.abs(torch.randn((num_iterations, num_edges))))\n",
    "        self.W_cv.requires_grad = True\n",
    "        self.B_cv = torch.nn.Parameter(torch.abs(torch.randn((num_iterations, num_edges))))\n",
    "        self.B_cv.requires_grad = True\n",
    "        self.W_vc = torch.nn.Parameter(torch.abs(torch.randn((num_iterations, num_edges))))\n",
    "        self.W_vc.requires_grad = True\n",
    "\n",
    "        self.num_iterations = num_iterations\n",
    "        \n",
    "    def forward(self, soft_input):\n",
    "        cv = torch.zeros((num_edges, soft_input.shape[1]))\n",
    "        for iteration in range(0, self.num_iterations):\n",
    "            vc = self.compute_vc(cv, soft_input, iteration)\n",
    "            cv = self.compute_cv(vc, iteration)\n",
    "            soft_input = self.marginalize(soft_input, cv)\n",
    "        output = torch.sigmoid(soft_input)\n",
    "        # output = soft_input\n",
    "        return output\n",
    "\n",
    "        \n",
    "    def compute_vc(self, cv, soft_input, iteration):\n",
    "        edges = []\n",
    "        for i in range(0, n):\n",
    "            for j in range(0, var_degrees[i]):\n",
    "                edges.append(i)\n",
    "\n",
    "        reordered_soft_input = torch.index_select(soft_input, 0, torch.tensor(edges).to(device))\n",
    "\n",
    "        vc = []\n",
    "        edge_order = []\n",
    "\n",
    "        for i in range(0, n): # for each variable node v\n",
    "            for j in range(0, var_degrees[i]):\n",
    "                edge_order.append(d[i][j])\n",
    "                extrinsic_edges = []\n",
    "                for jj in range(0, var_degrees[i]):\n",
    "                    if jj != j: # extrinsic information only\n",
    "                        extrinsic_edges.append(d[i][jj])\n",
    "                # if the list of edges is not empty, add them up\n",
    "                if extrinsic_edges:\n",
    "                    temp = torch.index_select(cv.to(device), 0, torch.tensor(extrinsic_edges).to(device))\n",
    "                    temp = torch.sum(temp, 0)\n",
    "                else:\n",
    "                    temp = torch.zeros(cv.shape[1])\n",
    "                vc.append(temp)\n",
    "        # vc = torch.tensor(vc)\n",
    "        vc = torch.stack(vc)\n",
    "        new_order = np.zeros(num_edges).astype(int)\n",
    "        new_order[edge_order] = np.arange(0, num_edges)\n",
    "        vc = torch.index_select(vc, 0, torch.tensor(new_order).to(device))\n",
    "        vc += reordered_soft_input * torch.tile(torch.reshape(self.W_vc[iteration], (-1,1)), (1, cv.shape[1]))       # add soft inputs of the previous iterations!\n",
    "        return vc \n",
    "\n",
    "    def compute_cv(self, vc, iteration):\n",
    "        cv_list = []\n",
    "        prod_list = []\n",
    "        min_list = []\n",
    "        edge_order = []\n",
    "        for i in range(0, m): # for each check node c\n",
    "            for j in range(0, chk_degrees[i]):\n",
    "                edge_order.append(u[i][j])\n",
    "                extrinsic_edges = []\n",
    "                for jj in range(0, chk_degrees[i]):\n",
    "                    if jj != j:\n",
    "                        extrinsic_edges.append(u[i][jj])\n",
    "                temp = torch.index_select(vc.to(device),0,torch.tensor(extrinsic_edges).to(device))\n",
    "                temp1 = torch.prod(torch.sign(temp),0)\n",
    "                temp2 = torch.min(torch.abs(temp),0)[0]\n",
    "                prod_list.append(temp1)\n",
    "                min_list.append(temp2)\n",
    "        prods = torch.stack(prod_list)\n",
    "        mins = torch.stack(min_list)\n",
    "        mins = torch.relu(mins - torch.tile(torch.reshape(self.B_cv[iteration], (-1,1)), (1, vc.shape[1])))\n",
    "        cv = prods * mins\n",
    "        new_order = np.zeros(num_edges).astype(int)\n",
    "        new_order[edge_order] = np.array(range(0,num_edges)).astype(int)\n",
    "        cv = torch.index_select(cv, 0, torch.tensor(new_order).to(device))\n",
    "        cv = cv * torch.tile(torch.reshape(self.W_cv[iteration], (-1,1)), (1, vc.shape[1]))\n",
    "        return cv\n",
    "\n",
    "    # combine messages to get posterior LLRs\n",
    "    def marginalize(self, soft_input, cv):\n",
    "        weighted_soft_input = soft_input\n",
    "        soft_output = []\n",
    "        for i in range(0,n):\n",
    "            edges = []\n",
    "            for e in range(0,var_degrees[i]):\n",
    "                edges.append(d[i][e])\n",
    "            temp = torch.index_select(cv,0,torch.tensor(edges).to(device))\n",
    "            temp = torch.sum(temp, 0)\n",
    "            soft_output.append(temp)\n",
    "        soft_output = torch.stack(soft_output)\n",
    "        soft_output = weighted_soft_input + soft_output\n",
    "        return soft_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(loader, clf, criterion, opt):\n",
    "    clf.train(True)\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    correct = 0\n",
    "    # load batch\n",
    "    for model_input, target in loader:\n",
    "        # move data to device\n",
    "        model_input = model_input.to(device)\n",
    "        target = target.to(device)\n",
    "        # calculate outputs, loss and accuracy\n",
    "        model_output = clf(model_input)\n",
    "        loss = criterion(model_output, target)\n",
    "        avg_loss += loss\n",
    "        correct += torch.count_nonzero(torch.heaviside(model_output-0.5, torch.tensor([0.])) == target)\n",
    "        # calculate grad, upd weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    avg_loss = avg_loss / len(loader)\n",
    "    avg_acc = correct / len(loader.dataset)\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def epoch_test(loader, clf, criterion):\n",
    "    clf.eval()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    correct = 0\n",
    "    # load batch\n",
    "    for model_input, target in loader:\n",
    "        # move data to device\n",
    "        model_input = model_input.to(device)\n",
    "        target = target.to(device)\n",
    "        # calculate outputs, loss and accuracy\n",
    "        model_output = clf(model_input)\n",
    "        loss = criterion(model_output, target)\n",
    "        avg_loss += loss\n",
    "        correct += torch.count_nonzero(torch.heaviside(model_output-0.5, torch.tensor([0.])) == target)\n",
    "    avg_loss = avg_loss / len(loader)\n",
    "    avg_acc = correct / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def train(train_loader, test_loader, clf, criterion, opt, n_epochs=50):\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_loss, train_acc = epoch_train(train_loader, clf, criterion, opt)\n",
    "        test_loss, test_acc = epoch_test(test_loader, clf, criterion)\n",
    "\n",
    "        if (np.mod(epoch+1,100)==0):\n",
    "            print(f'[Epoch {epoch + 1}] train loss: {train_loss:.3f}; train acc: {train_acc:.2f}; ' + \n",
    "                  f'test loss: {test_loss:.3f}; test acc: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = np.random.randint(0,2,[k,batch_size])\n",
    "codewords = np.dot(G, messages) % 2\n",
    "BPSK_codewords = (0.5 - codewords.astype(np.float32)) * 2.0\n",
    "soft_input = np.zeros_like(BPSK_codewords)\n",
    "channel_information = np.zeros_like(BPSK_codewords)\n",
    "SNRs = np.arange(1,6)\n",
    "for i in range(0,len(SNRs)):\n",
    "    sigma = np.sqrt(1. / (2 * (np.float(k)/np.float(n)) * 10**(SNRs[i]/10)))\n",
    "    noise = sigma * np.random.randn(n,batch_size//len(SNRs))\n",
    "    start_idx = batch_size*i//len(SNRs)\n",
    "    end_idx = batch_size*(i+1)//len(SNRs)\n",
    "    soft_input[:,start_idx:end_idx] = BPSK_codewords[:,start_idx:end_idx] + noise\n",
    "\n",
    "tensor_x = torch.Tensor(soft_input) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(codewords)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=120, shuffle=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(num_iterations=5).to(device)\n",
    "opt = torch.optim.Adam(decoder.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▏                                                                                                                  | 109/2500 [00:02<00:50, 47.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 100] train loss: 295.776; train acc: 10.29; test loss: 296.759; test acc: 8.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████████                                                                                                              | 209/2500 [00:04<00:47, 47.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 200] train loss: 295.934; train acc: 10.43; test loss: 296.042; test acc: 10.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████▊                                                                                                         | 309/2500 [00:06<00:45, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 300] train loss: 296.944; train acc: 9.00; test loss: 297.061; test acc: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████▋                                                                                                    | 409/2500 [00:08<00:43, 47.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 400] train loss: 295.680; train acc: 11.71; test loss: 296.731; test acc: 10.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████████▍                                                                                               | 509/2500 [00:10<00:41, 47.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 500] train loss: 295.052; train acc: 16.00; test loss: 294.811; test acc: 13.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████████▏                                                                                          | 609/2500 [00:12<00:39, 47.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 600] train loss: 294.154; train acc: 17.86; test loss: 295.488; test acc: 17.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████████████                                                                                      | 709/2500 [00:14<00:37, 47.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 700] train loss: 294.775; train acc: 22.14; test loss: 293.599; test acc: 24.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████████▊                                                                                 | 809/2500 [00:17<00:35, 47.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 800] train loss: 292.674; train acc: 29.00; test loss: 291.996; test acc: 32.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████████▋                                                                            | 909/2500 [00:19<00:33, 47.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 900] train loss: 291.160; train acc: 31.86; test loss: 291.145; test acc: 32.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████                                                                       | 1009/2500 [00:21<00:31, 47.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000] train loss: 291.454; train acc: 29.71; test loss: 291.678; test acc: 31.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████████▊                                                                  | 1109/2500 [00:23<00:29, 47.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1100] train loss: 285.165; train acc: 58.14; test loss: 285.350; test acc: 53.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████████████████▌                                                             | 1209/2500 [00:25<00:27, 47.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1200] train loss: 277.895; train acc: 78.86; test loss: 278.194; test acc: 78.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████▎                                                        | 1309/2500 [00:27<00:24, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1300] train loss: 272.532; train acc: 89.29; test loss: 275.342; test acc: 82.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████████████████████████████                                                    | 1409/2500 [00:29<00:22, 47.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1400] train loss: 275.116; train acc: 84.00; test loss: 271.824; test acc: 90.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████████▊                                               | 1509/2500 [00:31<00:20, 47.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1500] train loss: 275.171; train acc: 83.43; test loss: 271.968; test acc: 90.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████████████████████████████▌                                          | 1609/2500 [00:33<00:18, 47.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1600] train loss: 274.209; train acc: 84.14; test loss: 274.767; test acc: 83.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████████████████████████████████▎                                     | 1709/2500 [00:35<00:16, 47.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1700] train loss: 272.157; train acc: 89.14; test loss: 269.275; test acc: 94.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████████████████████████████████                                 | 1809/2500 [00:37<00:14, 47.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1800] train loss: 275.204; train acc: 82.71; test loss: 272.342; test acc: 88.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████▊                            | 1909/2500 [00:40<00:12, 47.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1900] train loss: 274.486; train acc: 83.86; test loss: 274.534; test acc: 83.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████▋                       | 2009/2500 [00:42<00:10, 47.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2000] train loss: 268.340; train acc: 96.43; test loss: 275.305; test acc: 82.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 2109/2500 [00:44<00:08, 47.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2100] train loss: 275.109; train acc: 82.14; test loss: 275.459; test acc: 82.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 2209/2500 [00:46<00:06, 47.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2200] train loss: 275.469; train acc: 83.00; test loss: 271.488; test acc: 91.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 2309/2500 [00:48<00:03, 47.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2300] train loss: 264.975; train acc: 109.00; test loss: 273.827; test acc: 90.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 2409/2500 [00:50<00:01, 47.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2400] train loss: 269.826; train acc: 98.86; test loss: 270.532; test acc: 97.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:52<00:00, 47.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2500] train loss: 270.875; train acc: 96.00; test loss: 269.515; test acc: 99.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(loader, loader, decoder, criterion, opt, n_epochs=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(778)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(torch.round(decoder(tensor_x)) == tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
