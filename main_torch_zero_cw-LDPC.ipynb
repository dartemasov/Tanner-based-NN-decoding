{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyldpc as ldpc\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from utils_f import load_code\n",
    "import os\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_filename = './source/LDPC_N96_K48_P8_set0_dmin10.alist'\n",
    "code = load_code(H_filename)\n",
    "H = code.H\n",
    "G = code.G\n",
    "var_degrees = code.var_degrees\n",
    "chk_degrees = code.chk_degrees\n",
    "num_edges = code.num_edges\n",
    "u = code.u\n",
    "d = code.d\n",
    "n = code.n\n",
    "m = code.m\n",
    "k = code.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class min_sum(torch.nn.Module):\n",
    "    def __init__(self, num_iterations = 5):\n",
    "        super(min_sum, self).__init__()\n",
    "        self.W_cv = torch.ones((num_iterations, num_edges))\n",
    "        # self.W_cv = torch.nn.Parameter(torch.abs(torch.ones((num_iterations, num_edges))))\n",
    "        # self.W_cv.requires_grad = True\n",
    "        self.B_cv = torch.zeros((num_iterations, num_edges))\n",
    "        # self.B_cv = torch.nn.Parameter(torch.abs(torch.zeros((num_iterations, num_edges))))\n",
    "        # self.B_cv.requires_grad = True\n",
    "        self.W_vc = torch.ones((num_iterations, num_edges))\n",
    "        # self.W_vc = torch.nn.Parameter(torch.abs(torch.ones((num_iterations, num_edges))))\n",
    "        # self.W_vc.requires_grad = True\n",
    "        \n",
    "        self.num_iterations = num_iterations\n",
    "        \n",
    "    def forward(self, soft_input):\n",
    "        soft_input = soft_input.T           # TODO! Fix matrix dimensions inside functions\n",
    "        # print(soft_input.shape)\n",
    "        cv = torch.zeros((num_edges, soft_input.shape[1]))\n",
    "        for iteration in range(0, self.num_iterations):\n",
    "            vc = self.compute_vc(cv, soft_input, iteration)\n",
    "            cv = self.compute_cv(vc, iteration)\n",
    "            soft_input = self.marginalize(soft_input, cv)\n",
    "        output = torch.sigmoid(-soft_input)\n",
    "        output = output.T\n",
    "        \n",
    "        # self.W_cv = torch.nn.Parameter(torch.abs(self.W_cv))\n",
    "        # self.B_cv =torch.nn.Parameter(torch.abs(self.B_cv))\n",
    "        # self.W_vc = torch.nn.Parameter(torch.abs(self.W_vc))\n",
    "        # output = soft_input\n",
    "        return output\n",
    "\n",
    "        \n",
    "    def compute_vc(self, cv, soft_input, iteration):\n",
    "        edges = []\n",
    "        for i in range(0, n):\n",
    "            for j in range(0, var_degrees[i]):\n",
    "                edges.append(i)\n",
    "        # print(soft_input.shape, len(edges), edges)\n",
    "        reordered_soft_input = torch.index_select(soft_input, 0, torch.tensor(edges).to(device))\n",
    "\n",
    "        vc = torch.zeros((num_edges, cv.shape[1])).to(device)\n",
    "        counter = 0\n",
    "        edge_order = []\n",
    "\n",
    "        for i in range(0, n): # for each variable node v\n",
    "            for j in range(0, var_degrees[i]):\n",
    "                edge_order.append(d[i][j])\n",
    "                extrinsic_edges = []\n",
    "                for jj in range(0, var_degrees[i]):\n",
    "                    if jj != j: # extrinsic information only\n",
    "                        extrinsic_edges.append(d[i][jj])\n",
    "                # if the list of edges is not empty, add them up\n",
    "                if extrinsic_edges:\n",
    "                    # print(cv.shape, len(extrinsic_edges), extrinsic_edges)\n",
    "                    temp = torch.index_select(cv.to(device), 0, torch.tensor(extrinsic_edges).to(device))\n",
    "                    temp = torch.sum(temp, 0)\n",
    "                else:\n",
    "                    temp = torch.zeros(cv.shape[1])\n",
    "\n",
    "                temp = temp.to(device)\n",
    "                vc[counter] = temp\n",
    "        \n",
    "        new_order = np.zeros(num_edges).astype(int)\n",
    "        new_order[edge_order] = np.arange(0, num_edges)\n",
    "        vc = torch.index_select(vc, 0, torch.tensor(new_order).to(device))\n",
    "        vc += reordered_soft_input * torch.tile(torch.reshape(self.W_vc[iteration], (-1,1)), (1, cv.shape[1])).to(device)       # add soft inputs of the previous iterations!\n",
    "        return vc \n",
    "\n",
    "    def compute_cv(self, vc, iteration):\n",
    "        cv_list = []\n",
    "        prod_list = []\n",
    "        min_list = []\n",
    "        edge_order = []\n",
    "        for i in range(0, m): # for each check node c\n",
    "            for j in range(0, chk_degrees[i]):\n",
    "                edge_order.append(u[i][j])\n",
    "                extrinsic_edges = []\n",
    "                for jj in range(0, chk_degrees[i]):\n",
    "                    if jj != j:\n",
    "                        extrinsic_edges.append(u[i][jj])\n",
    "                temp = torch.index_select(vc.to(device),0,torch.tensor(extrinsic_edges).to(device))\n",
    "                temp1 = torch.prod(torch.sign(temp),0)\n",
    "                temp2 = torch.min(torch.abs(temp),0)[0]\n",
    "                prod_list.append(temp1)\n",
    "                min_list.append(temp2)\n",
    "        prods = torch.stack(prod_list)\n",
    "        mins = torch.stack(min_list)\n",
    "        mins = torch.relu(mins - torch.tile(torch.reshape(self.B_cv[iteration], (-1,1)), (1, vc.shape[1])).to(device))\n",
    "        cv = prods * mins\n",
    "        new_order = np.zeros(num_edges).astype(int)\n",
    "        new_order[edge_order] = np.array(range(0,num_edges)).astype(int)\n",
    "        cv = torch.index_select(cv, 0, torch.tensor(new_order).to(device))\n",
    "        cv = cv * torch.tile(torch.reshape(self.W_cv[iteration], (-1,1)), (1, vc.shape[1])).to(device)\n",
    "        return cv\n",
    "\n",
    "    # combine messages to get posterior LLRs\n",
    "    def marginalize(self, soft_input, cv):\n",
    "        weighted_soft_input = soft_input\n",
    "        soft_output = []\n",
    "        for i in range(0,n):\n",
    "            edges = []\n",
    "            for e in range(0,var_degrees[i]):\n",
    "                edges.append(d[i][e])\n",
    "            temp = torch.index_select(cv,0,torch.tensor(edges).to(device))\n",
    "            temp = torch.sum(temp, 0)\n",
    "            soft_output.append(temp)\n",
    "        soft_output = torch.stack(soft_output)\n",
    "        soft_output = weighted_soft_input + soft_output\n",
    "        return soft_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, num_iterations = 5):\n",
    "        super(Decoder, self).__init__()\n",
    "        # self.W_cv = torch.ones((num_iterations, num_edges))\n",
    "        self.W_cv = torch.nn.Parameter(torch.abs(torch.randn((num_iterations, num_edges))))\n",
    "        self.W_cv.requires_grad = True\n",
    "        # self.B_cv = torch.zeros((num_iterations, num_edges))\n",
    "        self.B_cv = torch.nn.Parameter(torch.abs(torch.randn((num_iterations, num_edges))))\n",
    "        self.B_cv.requires_grad = True\n",
    "        # self.W_vc = torch.ones((num_iterations, num_edges))\n",
    "        self.W_vc = torch.nn.Parameter(torch.abs(torch.randn((num_iterations, num_edges))))\n",
    "        self.W_vc.requires_grad = True\n",
    "        \n",
    "        self.num_iterations = num_iterations\n",
    "        \n",
    "    def forward(self, soft_input):\n",
    "        soft_input = soft_input.T           # TODO! Fix matrix dimensions inside functions\n",
    "        # print(soft_input.shape)\n",
    "        cv = torch.zeros((num_edges, soft_input.shape[1]))\n",
    "        for iteration in range(0, self.num_iterations):\n",
    "            vc = self.compute_vc(cv, soft_input, iteration)\n",
    "            cv = self.compute_cv(vc, iteration)\n",
    "            soft_input = self.marginalize(soft_input, cv)\n",
    "        output = torch.sigmoid(-soft_input)\n",
    "        output = output.T\n",
    "        \n",
    "        # self.W_cv = torch.nn.Parameter(torch.abs(self.W_cv))\n",
    "        # self.B_cv =torch.nn.Parameter(torch.abs(self.B_cv))\n",
    "        # self.W_vc = torch.nn.Parameter(torch.abs(self.W_vc))\n",
    "        \n",
    "        # output = soft_input\n",
    "        return output\n",
    "\n",
    "        \n",
    "    def compute_vc(self, cv, soft_input, iteration):\n",
    "        edges = []\n",
    "        for i in range(0, n):\n",
    "            for j in range(0, var_degrees[i]):\n",
    "                edges.append(i)\n",
    "        # print(soft_input.shape, len(edges), edges)\n",
    "        reordered_soft_input = torch.index_select(soft_input, 0, torch.tensor(edges).to(device))\n",
    "\n",
    "        vc = torch.zeros((num_edges, cv.shape[1])).to(device)\n",
    "        counter = 0\n",
    "        edge_order = []\n",
    "\n",
    "        for i in range(0, n): # for each variable node v\n",
    "            for j in range(0, var_degrees[i]):\n",
    "                edge_order.append(d[i][j])\n",
    "                extrinsic_edges = []\n",
    "                for jj in range(0, var_degrees[i]):\n",
    "                    if jj != j: # extrinsic information only\n",
    "                        extrinsic_edges.append(d[i][jj])\n",
    "                # if the list of edges is not empty, add them up\n",
    "                if extrinsic_edges:\n",
    "                    # print(cv.shape, len(extrinsic_edges), extrinsic_edges)\n",
    "                    temp = torch.index_select(cv.to(device), 0, torch.tensor(extrinsic_edges).to(device))\n",
    "                    temp = torch.sum(temp, 0)\n",
    "                else:\n",
    "                    temp = torch.zeros(cv.shape[1])\n",
    "\n",
    "                temp = temp.to(device)\n",
    "                vc[counter] = temp\n",
    "        \n",
    "        new_order = np.zeros(num_edges).astype(int)\n",
    "        new_order[edge_order] = np.arange(0, num_edges)\n",
    "        vc = torch.index_select(vc, 0, torch.tensor(new_order).to(device))\n",
    "        vc += reordered_soft_input * torch.tile(torch.reshape(self.W_vc[iteration], (-1,1)), (1, cv.shape[1]))       # add soft inputs of the previous iterations!\n",
    "        return vc \n",
    "\n",
    "    def compute_cv(self, vc, iteration):\n",
    "        cv_list = []\n",
    "        prod_list = []\n",
    "        min_list = []\n",
    "        edge_order = []\n",
    "        for i in range(0, m): # for each check node c\n",
    "            for j in range(0, chk_degrees[i]):\n",
    "                edge_order.append(u[i][j])\n",
    "                extrinsic_edges = []\n",
    "                for jj in range(0, chk_degrees[i]):\n",
    "                    if jj != j:\n",
    "                        extrinsic_edges.append(u[i][jj])\n",
    "                temp = torch.index_select(vc.to(device),0,torch.tensor(extrinsic_edges).to(device))\n",
    "                temp1 = torch.prod(torch.sign(temp),0)\n",
    "                temp2 = torch.min(torch.abs(temp),0)[0]\n",
    "                prod_list.append(temp1)\n",
    "                min_list.append(temp2)\n",
    "        prods = torch.stack(prod_list)\n",
    "        mins = torch.stack(min_list)\n",
    "        mins = torch.relu(mins - torch.tile(torch.reshape(self.B_cv[iteration], (-1,1)), (1, vc.shape[1])))\n",
    "        cv = prods * mins\n",
    "        new_order = np.zeros(num_edges).astype(int)\n",
    "        new_order[edge_order] = np.array(range(0,num_edges)).astype(int)\n",
    "        cv = torch.index_select(cv, 0, torch.tensor(new_order).to(device))\n",
    "        cv = cv * torch.tile(torch.reshape(self.W_cv[iteration], (-1,1)), (1, vc.shape[1]))\n",
    "        return cv\n",
    "\n",
    "    # combine messages to get posterior LLRs\n",
    "    def marginalize(self, soft_input, cv):\n",
    "        weighted_soft_input = soft_input\n",
    "        soft_output = []\n",
    "        for i in range(0,n):\n",
    "            edges = []\n",
    "            for e in range(0,var_degrees[i]):\n",
    "                edges.append(d[i][e])\n",
    "            temp = torch.index_select(cv,0,torch.tensor(edges).to(device))\n",
    "            temp = torch.sum(temp, 0)\n",
    "            soft_output.append(temp)\n",
    "        soft_output = torch.stack(soft_output)\n",
    "        soft_output = weighted_soft_input + soft_output\n",
    "        return soft_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(loader, clf, criterion, opt):\n",
    "    clf.train(True)\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    correct = 0\n",
    "    # load batch\n",
    "    for model_input, target in loader:\n",
    "        # move data to device\n",
    "        model_input = model_input.to(device)\n",
    "        target = target.to(device)\n",
    "        # calculate outputs, loss and accuracy\n",
    "        model_output = clf(model_input)\n",
    "        loss = criterion(model_output, target)\n",
    "        # print(model_input[0], model_output[0])\n",
    "        avg_loss += loss\n",
    "        correct += torch.count_nonzero(torch.heaviside(model_output-0.5, torch.tensor([0.]).to(device)).to(device) == target)\n",
    "        # calculate grad, upd weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    avg_loss = avg_loss / len(loader)\n",
    "    avg_acc = correct / len(loader.dataset)\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "            \n",
    "            \n",
    "                        \n",
    "def epoch_test(loader, clf, criterion):\n",
    "    clf.eval()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    correct = 0\n",
    "    # load batch\n",
    "    for model_input, target in loader:\n",
    "        # move data to device\n",
    "        model_input = model_input.to(device)\n",
    "        target = target.to(device)\n",
    "        # calculate outputs, loss and accuracy\n",
    "        model_output = clf(model_input)\n",
    "        loss = criterion(model_output, target)\n",
    "        avg_loss += loss\n",
    "        correct += torch.count_nonzero(torch.heaviside(model_output-0.5, torch.tensor([0.]).to(device)).to(device) == target)\n",
    "    avg_loss = avg_loss / len(loader)\n",
    "    avg_acc = correct / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def train(train_loader, test_loader, clf, criterion, opt, n_epochs=50):\n",
    "    for epoch in trange(n_epochs):\n",
    "        train_loss, train_acc = epoch_train(train_loader, clf, criterion, opt)\n",
    "        test_loss, test_acc = epoch_test(test_loader, clf, criterion)\n",
    "        # clf.apply(constraints)\n",
    "\n",
    "        # clf.W_cv = torch.nn.Parameter(torch.relu(clf.W_cv))\n",
    "        # clf.B_cv = torch.nn.Parameter(torch.relu(clf.B_cv))\n",
    "        # clf.W_vc = torch.nn.Parameter(torch.relu(clf.W_vc))\n",
    "        # print(clf.W_cv[0])\n",
    "\n",
    "\n",
    "        if (np.mod(epoch+1,1)==0):\n",
    "            print(f'[Epoch {epoch + 1}] train loss: {train_loss:.3f}; train acc: {train_acc:.2f}; ' + \n",
    "                  f'test loss: {test_loss:.3f}; test acc: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    # messages = np.random.randint(0,2,[train_size,k])\n",
    "    # codewords = messages @ G % 2\n",
    "    # BPSK_codewords = (0.5 - codewords.astype(np.float32)) * 2.0\n",
    "    codewords = torch.ones((train_size, n)).to(device)\n",
    "    BPSK_codewords = -1*torch.ones_like(codewords).to(device)\n",
    "    soft_input = torch.zeros_like(BPSK_codewords).to(device)\n",
    "    SNRs = np.arange(1,6)\n",
    "    for i in range(0,len(SNRs)):\n",
    "        sigma = torch.sqrt(torch.tensor(1) / (2 * (k/n) * 10**(SNRs[i]/10))).to(device)\n",
    "        noise = sigma * torch.randn((train_size//len(SNRs),n)).to(device)\n",
    "        start_idx = train_size*i//len(SNRs)\n",
    "        end_idx = train_size*(i+1)//len(SNRs)\n",
    "        soft_input[start_idx:end_idx,:] = BPSK_codewords[start_idx:end_idx,:] + noise\n",
    "        soft_input = 2 * soft_input / (sigma**2)\n",
    "    return soft_input, codewords\n",
    "    \n",
    "def update_loaders():\n",
    "\n",
    "    soft_input_train, codewords_train = gen()\n",
    "    train_X = soft_input_train # transform to torch tensor\n",
    "    train_y = codewords_train\n",
    "    training_dataset = torch.utils.data.TensorDataset(train_X, train_y) # create your datset\n",
    "    training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=20000, shuffle=True) # create your dataloader\n",
    "\n",
    "\n",
    "    soft_input_test, codewords_test = gen()\n",
    "    test_X = soft_input_test # transform to torch tensor\n",
    "    test_y = codewords_test\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_X, test_y) # create your datset\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=20000, shuffle=True) # create your dataloader\n",
    "    return training_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(num_iterations=5).to(device)\n",
    "# opt = torch.optim.Adam(decoder.parameters(), lr=0.0025)\n",
    "opt = torch.optim.SGD(decoder.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_size = 10000\n",
    "req_err = 500*n\n",
    "SNRs = np.arange(-10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m soft_input \u001b[38;5;241m=\u001b[39m BPSK_codewords \u001b[38;5;241m+\u001b[39m noise\n\u001b[1;32m     23\u001b[0m frame_errors_hard[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39many((\u001b[38;5;241m-\u001b[39m(torch\u001b[38;5;241m.\u001b[39msign(soft_input[:,n\u001b[38;5;241m-\u001b[39mk:]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m!=\u001b[39m codewords[:,n\u001b[38;5;241m-\u001b[39mk:], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 24\u001b[0m frame_errors_min_sum[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39mheaviside(\u001b[43mms\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoft_input\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)) \u001b[38;5;241m!=\u001b[39m codewords, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     25\u001b[0m bit_errors_hard[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcount_nonzero((\u001b[38;5;241m-\u001b[39m(torch\u001b[38;5;241m.\u001b[39msign(soft_input) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m!=\u001b[39m codewords)\n\u001b[1;32m     26\u001b[0m bit_errors_min_sum[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcount_nonzero(torch\u001b[38;5;241m.\u001b[39mheaviside(ms(soft_input) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)) \u001b[38;5;241m!=\u001b[39m codewords)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mmin_sum.forward\u001b[0;34m(self, soft_input)\u001b[0m\n\u001b[1;32m     19\u001b[0m cv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((num_edges, soft_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iterations):\n\u001b[0;32m---> 21\u001b[0m     vc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_vc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoft_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_cv(vc, iteration)\n\u001b[1;32m     23\u001b[0m     soft_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarginalize(soft_input, cv)\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mmin_sum.compute_vc\u001b[0;34m(self, cv, soft_input, iteration)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# if the list of edges is not empty, add them up\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extrinsic_edges:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# print(cv.shape, len(extrinsic_edges), extrinsic_edges)\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextrinsic_edges\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     temp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(temp, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# hard decisions, classic min-sum\n",
    "ms = min_sum(num_iterations=20).to(device)\n",
    "\n",
    "frame_errors_hard = torch.zeros(len(SNRs)).to(device)\n",
    "nb_frames_hard = torch.zeros(len(SNRs)).to(device)\n",
    "frame_errors_min_sum = torch.zeros(len(SNRs)).to(device)\n",
    "nb_frames_min_sum = torch.zeros(len(SNRs)).to(device)\n",
    "bit_errors_hard = torch.zeros(len(SNRs)).to(device)\n",
    "nb_bits_hard = torch.zeros(len(SNRs)).to(device)\n",
    "bit_errors_min_sum = torch.zeros(len(SNRs)).to(device)\n",
    "nb_bits_min_sum = torch.zeros(len(SNRs)).to(device)\n",
    "for i, snr in enumerate(SNRs):\n",
    "            while bit_errors_min_sum[i] < req_err:\n",
    "                # messages = torch.randint(0, 2, (test_size, k))\n",
    "                codewords = torch.ones((test_size, n)).to(device)\n",
    "                BPSK_codewords = -1*torch.ones_like(codewords).to(device)\n",
    "                # codewords = messages @ G % 2\n",
    "                # codewords = codewords.to(device)\n",
    "                # BPSK_codewords = (0.5 - codewords) * 2\n",
    "                sigma = torch.sqrt(torch.tensor(1) / (2 * (k/n) * 10**(snr/10)))\n",
    "                noise = sigma * torch.randn(test_size, n).to(device)\n",
    "                soft_input = BPSK_codewords + noise\n",
    "                frame_errors_hard[i] += torch.sum(torch.any((-(torch.sign(soft_input[:,n-k:]) - 1)/2) != codewords[:,n-k:], axis=1))\n",
    "                frame_errors_min_sum[i] += torch.sum(torch.any(torch.heaviside(ms(soft_input) - 0.5, torch.tensor([0.]).to(device)) != codewords, axis=1))\n",
    "                bit_errors_hard[i] += torch.count_nonzero((-(torch.sign(soft_input) - 1)/2) != codewords)\n",
    "                bit_errors_min_sum[i] += torch.count_nonzero(torch.heaviside(ms(soft_input) - 0.5, torch.tensor([0.]).to(device)) != codewords)\n",
    "                nb_bits_hard[i] += test_size * n\n",
    "                nb_bits_min_sum[i] += test_size * n\n",
    "                nb_frames_hard[i] += test_size\n",
    "                nb_frames_min_sum[i] += test_size\n",
    "                print(f'SNR: {snr}, {100*bit_errors_min_sum[i]/req_err :.3f}%, test BER: {bit_errors_min_sum[i] / nb_bits_min_sum[i]}, test FER: {frame_errors_min_sum[i] / nb_frames_min_sum[i]}                ', end='\\r')\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weightConstraint(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self,module):\n",
    "        if hasattr(module,'weight'):\n",
    "            print(\"Entered\")\n",
    "            W_cv=module.W_cv\n",
    "            W_cv = torch.clamp(W_cv, min=0)\n",
    "            module.W_cv=W_cv\n",
    "            B_cv=module.B_cv\n",
    "            B_cv = torch.clamp(W_cv, min=0)\n",
    "            module.B_cv=B_cv\n",
    "            W_vc=module.W_vc\n",
    "            W_vc = torch.clamp(W_vc, min=0)\n",
    "            module.W_vc=W_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints=weightConstraint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ITERATION #1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████                                                                                | 1/3 [00:01<00:02,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 40.777; train acc: 14.52; test loss: 40.774; test acc: 14.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████                                        | 2/3 [00:02<00:01,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss: 40.777; train acc: 14.52; test loss: 40.773; test acc: 14.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train loss: 40.776; train acc: 14.52; test loss: 40.774; test acc: 14.53\n",
      "TRAINING ITERATION #2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████                                                                                | 1/3 [00:01<00:02,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 40.776; train acc: 14.52; test loss: 40.774; test acc: 14.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████                                        | 2/3 [00:02<00:01,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss: 40.776; train acc: 14.52; test loss: 40.774; test acc: 14.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train loss: 40.775; train acc: 14.52; test loss: 40.773; test acc: 14.53\n",
      "TRAINING ITERATION #3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████                                                                                | 1/3 [00:01<00:03,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 40.776; train acc: 14.52; test loss: 40.775; test acc: 14.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████                                        | 2/3 [00:02<00:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss: 40.775; train acc: 14.52; test loss: 40.776; test acc: 14.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train loss: 40.775; train acc: 14.52; test loss: 40.775; test acc: 14.53\n",
      "TRAINING ITERATION #4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████████████████                                                                                | 1/3 [00:01<00:02,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 40.776; train acc: 14.52; test loss: 40.773; test acc: 14.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████                                        | 2/3 [00:02<00:01,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss: 40.776; train acc: 14.52; test loss: 40.772; test acc: 14.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train loss: 40.776; train acc: 14.52; test loss: 40.772; test acc: 14.53\n",
      "TRAINING ITERATION #5/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_size = 50000\n",
    "n_upd = 500\n",
    "bit_errors_nn = torch.zeros((n_upd, len(SNRs))).to(device)\n",
    "nb_bits_nn = torch.zeros((n_upd, len(SNRs))).to(device)\n",
    "ber_list = []\n",
    "\n",
    "for upd in range(n_upd):\n",
    "    print(f'TRAINING ITERATION #{upd+1}/{n_upd}')\n",
    "    training_loader, test_loader = update_loaders()\n",
    "    train(training_loader, test_loader, decoder, criterion, opt, n_epochs=3)\n",
    "\n",
    "    if (np.mod(upd+1,5)==0):\n",
    "        decoder.eval()\n",
    "        for i, snr in enumerate(SNRs):\n",
    "            while bit_errors_nn[upd][i] < req_err:\n",
    "                messages = torch.randint(0, 2, (test_size, k))\n",
    "                codewords = messages @ G % 2\n",
    "                codewords = codewords.to(device)\n",
    "                BPSK_codewords = (0.5 - codewords) * 2\n",
    "                # codewords = torch.ones((test_size, n)).to(device)\n",
    "                # BPSK_codewords = -1*torch.ones_like(codewords).to(device)\n",
    "                sigma = torch.sqrt(torch.tensor(1) / (2 * (np.float(k)/np.float(n)) * 10**(snr/10)))\n",
    "                noise = sigma * torch.randn(test_size, n).to(device)\n",
    "                soft_input = BPSK_codewords + noise\n",
    "                bit_errors_nn[upd][i] += torch.count_nonzero(torch.heaviside(decoder(soft_input) - 0.5, torch.tensor([0.]).to(device)) != codewords)\n",
    "                nb_bits_nn[upd][i] += test_size * n\n",
    "                print(f'SNR: {snr}, {100*bit_errors_nn[upd][i]/req_err :.3f}%, test BER: {bit_errors_nn[upd][i] / nb_bits_nn[upd][i]}                ', end='\\r')\n",
    "            print('\\n')\n",
    "        ber_list.append((bit_errors_nn[upd,-1].cpu() / nb_bits_nn[upd,-1].cpu()).numpy())    \n",
    "        np.savetxt('ber.txt', ber_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.semilogy(SNRs, bit_errors_min_sum.cpu() / nb_bits_min_sum.cpu(), label='Classical Min-sum')\n",
    "plt.semilogy(SNRs, bit_errors_hard.cpu() / nb_bits_hard.cpu(), label='hard decision')\n",
    "# for i in range(10):\n",
    "plt.semilogy(SNRs, bit_errors_nn[77].cpu() / nb_bits_nn[77].cpu(), label=f'NN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder(soft_input)[0] - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codewords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.W_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.B_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
